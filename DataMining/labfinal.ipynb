# Import required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score

# ----------------------------
# 1Ô∏è‚É£ Load dataset
# ----------------------------
data = pd.read_csv("https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv")
print("‚úÖ Dataset loaded successfully\n")
print(data.head())

# ----------------------------
# 2Ô∏è‚É£ Check and handle missing values
# ----------------------------
print("\nüîç Missing Value Count:")
print(data.isnull().sum())

# Fill missing values with mean
data = data.fillna(data.mean(numeric_only=True))
print("\n‚úÖ After handling missing values:")
print(data.isnull().sum())

# ----------------------------
# 3Ô∏è‚É£ Add/Delete/Merge Columns
# ----------------------------

# Add new column (example: ratio)
data["petal_ratio"] = data["petal_length"] / data["petal_width"]

# üß© Add a new column *before* a specific column (example: before 'species')
new_col_name = "sepal_area"
data.insert(loc=data.columns.get_loc("species"), column=new_col_name, 
            value=data["sepal_length"] * (data["petal_width"]))

# üóëÔ∏è Delete a specific column (example: remove 'sepal_length')
data.drop(columns=["sepal_length"], inplace=True)

# Merge two columns (create new column)
data["merged_col"] = data["species"] + "_" + data["petal_length"].astype(str)

print("\n‚úÖ After adding before, deleting, and merging columns:")
print(data.head())

# ----------------------------
# 4Ô∏è‚É£ Encode categorical data
# ----------------------------
le = LabelEncoder()
data["species_encoded"] = le.fit_transform(data["species"])

# ----------------------------
# 5Ô∏è‚É£ Feature Scaling (Normalization)
# ----------------------------
scaler = StandardScaler()
num_features = ["petal_length", "petal_width", "sepal_area"]
data[num_features] = scaler.fit_transform(data[num_features])

# ----------------------------
# 6Ô∏è‚É£ Train-Test Split
# ----------------------------
X = data[["petal_length", "petal_width", "sepal_area"]]
y = data["species_encoded"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ----------------------------
# 7Ô∏è‚É£ Train and Evaluate Multiple Models
# ----------------------------
models = {
    "Logistic Regression": LogisticRegression(max_iter=200),
    "KNN": KNeighborsClassifier(n_neighbors=5),
    "Decision Tree": DecisionTreeClassifier(random_state=42)
}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"\nüìä {name} Results:")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Precision (macro):", precision_score(y_test, y_pred, average="macro"))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("Classification Report:\n", classification_report(y_test, y_pred))

# ----------------------------
# 8Ô∏è‚É£ Condition-based filtering
# ----------------------------
val = 0.0
filtered_data = data[data["petal_length"] < val]
print(f"\nüîé Rows where petal_length < {val}:")
print(filtered_data if not filtered_data.empty else "No data found!")

# ----------------------------
# 9Ô∏è‚É£ Subplots Visualization
# ----------------------------
fig, axes = plt.subplots(1, 2, figsize=(10, 4))

axes[0].hist(data["petal_length"], bins=20, color='skyblue')
axes[0].set_title("Petal Length Distribution")

axes[1].scatter(data["petal_width"], data["sepal_area"], c=data["species_encoded"], cmap='viridis')
axes[1].set_title("Petal Width vs Sepal Area")

plt.tight_layout()
plt.show()
